cidatapln_bin = ifelse(CIDATAPLN == 1, 1, ifelse(CIDATAPLN == 0, 0, NA)),
cihispeed_bin = case_when(
CIHISPEED %in% c(10, 20) ~ 1,
CIHISPEED == 0 ~ 0,
TRUE ~ NA_real_
)
)
data_recent <- data_recent %>%
mutate(
cismrtphn_bin = ifelse(is.na(cismrtphn_bin), 0, cismrtphn_bin)
)
data_recent <- data_recent %>%
rowwise() %>%
mutate(digital_index = mean(c(cilaptop_bin, cismrtphn_bin, cidatapln_bin, cihispeed_bin), na.rm = TRUE)) %>%
ungroup()
summary(data_recent)
cismrtphn_bin = ifelse(is.na(cismrtphn_bin), 0, cismrtphn_bin)
na_rates <- sapply(data_recent, function(x) mean(is.na(x)))
na_df <- data.frame(
variable = names(na_rates),
na_rate = round(na_rates, 4)
)
na_df <- na_df[order(-na_df$na_rate), ]
print(na_df)
data_model <- data_recent %>%
drop_na(cilaptop_bin, cismrtphn_bin, cidatapln_bin, cihispeed_bin)
summary(data_model)
write_csv(data_model, "./data/cleaned_data/data.csv")
library(readr)
write_csv(data_model, "./data/cleaned_data/data.csv")
file.exists("./data/cleaned_data/data.csv")
library(dplyr)
library(readr)
library(tidyr)
library(ggplot2)
data <- read_csv("./data/cleaned_data/data.csv")
# Data Aggregation(based on 'YEAR' and 'PUMA')
puma_panel <- data %>%
group_by(YEAR, PUMA) %>%
summarise(
avg_digital_index = mean(digital_index, na.rm = TRUE),
metro = first(METRO),
density = first(DENSITY),
.groups = "drop"
)
sigma_stats <- puma_panel %>%
group_by(YEAR) %>%
summarise(std_dev = sd(avg_digital_index, na.rm = TRUE))
ggplot(sigma_stats, aes(x = YEAR, y = std_dev)) +
geom_line() +
geom_point() +
labs(title = "σ-Convergence: Std Dev of Regional Digital Index",
y = "Standard Deviation", x = "Year") +
theme_minimal()
panel_wide <- puma_panel %>%
filter(YEAR %in% c(2013, 2023)) %>%
pivot_wider(names_from = YEAR, values_from = avg_digital_index, names_prefix = "y")
panel_wide <- panel_wide %>%
mutate(change = y2023 - y2013)
beta_model <- lm(change ~ y2013, data = panel_wide)
summary(panel_wide$y2013)
summary(panel_wide$y2023)
sum(panel_wide$y2013 > 0)
sum(panel_wide$y2023 > 0)
filtered <- panel_wide %>% filter(y2013 > 0, y2023 > 0)
nrow(filtered)
# Step 1: filtering
filtered <- panel_wide %>%
filter(!is.na(y2013), !is.na(y2023))
# Step 2: compute growth
filtered <- filtered %>%
mutate(change = y2023 - y2013)
# Step 3: run regression model
beta_model <- lm(change ~ y2013, data = filtered)
panel_2013_2023 <- puma_panel %>%
filter(YEAR %in% c(2013, 2023)) %>%
group_by(PUMA) %>%
filter(n() == 2) %>%
ungroup()
panel_wide <- panel_2013_2023 %>%
pivot_wider(names_from = YEAR, values_from = avg_digital_index, names_prefix = "y")
filtered <- panel_wide %>%
mutate(change = y2023 - y2013)
beta_model <- lm(change ~ y2013, data = filtered)
# 查看是否是 NA 问题
summary(panel_wide$y2013)
summary(panel_wide$y2023)
# 查看 NA 数量
sum(is.na(panel_wide$y2013))
sum(is.na(panel_wide$y2023))
# Step 1: 只保留 2013 和 2023 都有数据的 PUMA
panel_2013_2023 <- puma_panel %>%
filter(YEAR %in% c(2013, 2023)) %>%
group_by(PUMA) %>%
filter(n() == 2) %>%
ungroup()
# Step 2: 宽格式整理
panel_wide <- panel_2013_2023 %>%
pivot_wider(names_from = YEAR, values_from = avg_digital_index, names_prefix = "y")
# ✅ Step 3: 去除包含 NA 的行
filtered <- panel_wide %>%
filter(!is.na(y2013), !is.na(y2023)) %>%
mutate(change = y2023 - y2013)
# Step 4: 回归
beta_model <- lm(change ~ y2013, data = filtered)
na_summary <- puma_panel %>%
summarise(
total_rows = n(),
na_in_year = sum(is.na(YEAR)),
na_rate_year = round(mean(is.na(YEAR)), 4),
na_in_puma = sum(is.na(PUMA)),
na_rate_puma = round(mean(is.na(PUMA)), 4),
na_in_index = sum(is.na(avg_digital_index)),
na_rate_index = round(mean(is.na(avg_digital_index)), 4)
)
print(na_summary)
panel_2013_2023 <- puma_panel %>%
filter(YEAR %in% c(2013, 2023)) %>%
group_by(PUMA) %>%
filter(n() == 2) %>%
ungroup()
panel_wide <- panel_2013_2023 %>%
pivot_wider(names_from = YEAR, values_from = avg_digital_index, names_prefix = "y") %>%
filter(!is.na(y2013), !is.na(y2023)) %>%
mutate(change = y2023 - y2013)
beta_model <- lm(change ~ y2013, data = panel_wide)
nrow(panel_wide)
summary(data)
metro_panel <- data %>%
filter(!is.na(digital_index), YEAR %in% c(2013, 2023)) %>%
group_by(YEAR, METRO) %>%
summarise(
avg_digital_index = mean(digital_index, na.rm = TRUE),
.groups = "drop"
)
metro_wide <- metro_panel %>%
pivot_wider(names_from = YEAR, values_from = avg_digital_index, names_prefix = "y") %>%
filter(!is.na(y2013), !is.na(y2023)) %>%
mutate(change = y2023 - y2013)
beta_metro <- lm(change ~ y2013, data = metro_wide)
summary(beta_metro)
ggplot(metro_wide, aes(x = y2013, y = change, label = METRO)) +
geom_point(size = 3) +
geom_smooth(method = "lm", se = TRUE, color = "steelblue") +
geom_text(vjust = -0.5, size = 3.5) +
labs(
title = "β-Convergence Across METRO Types (2013–2023)",
x = "Digital Index in 2013",
y = "Change in Digital Index (2023 - 2013)"
) +
theme_minimal()
run_beta <- function(year_target) {
df <- metro_panel %>%
filter(YEAR %in% c(2013, year_target)) %>%
pivot_wider(names_from = YEAR, values_from = avg_index, names_prefix = "y") %>%
filter(!is.na(y2013), !is.na(!!sym(paste0("y", year_target)))) %>%
mutate(change = !!sym(paste0("y", year_target)) - y2013)
model <- lm(change ~ y2013, data = df)
data.frame(
year = year_target,
beta = coef(model)["y2013"],
p = summary(model)$coefficients["y2013", "Pr(>|t|)"],
r2 = summary(model)$r.squared
)
}
results <- do.call(rbind, lapply(2014:2023, run_beta))
run_beta <- function(year_target) {
year_var <- paste0("y", year_target)
df <- metro_panel %>%
filter(YEAR %in% c(2013, year_target)) %>%
pivot_wider(names_from = YEAR, values_from = avg_index, names_prefix = "y") %>%
filter(!is.na(y2013), !is.na(!!sym(year_var))) %>%
mutate(change = !!sym(year_var) - y2013)
model <- lm(change ~ y2013, data = df)
data.frame(
year = year_target,
beta = coef(model)["y2013"],
p = summary(model)$coefficients["y2013", "Pr(>|t|)"],
r2 = summary(model)$r.squared
)
}
results <- do.call(rbind, lapply(2014:2023, run_beta))
run_beta <- function(year_target) {
year_var <- paste0("y", year_target)
df <- metro_panel %>%
filter(YEAR %in% c(2013, year_target)) %>%
pivot_wider(names_from = YEAR, values_from = avg_index, names_prefix = "y") %>%
filter(!is.na(y2013), !is.na(!!sym(year_var))) %>%
mutate(change = !!sym(year_var) - y2013)
model <- lm(change ~ y2013, data = df)
data.frame(
year = year_target,
beta = coef(model)["y2013"],
p = summary(model)$coefficients["y2013", "Pr(>|t|)"],
r2 = summary(model)$r.squared
)
}
results <- do.call(rbind, lapply(2014:2023, run_beta))
run_beta <- function(year_target) {
year_var <- paste0("y", year_target)
df <- metro_panel %>%
filter(YEAR %in% c(2013, year_target)) %>%
pivot_wider(names_from = YEAR, values_from = avg_digital_index, names_prefix = "y") %>%
filter(!is.na(y2013), !is.na(!!sym(year_var))) %>%
mutate(change = !!sym(year_var) - y2013)
model <- lm(change ~ y2013, data = df)
data.frame(
year = year_target,
beta = coef(model)["y2013"],
p = summary(model)$coefficients["y2013", "Pr(>|t|)"],
r2 = summary(model)$r.squared
)
}
results <- do.call(rbind, lapply(2014:2023, run_beta))
metro_panel <- data %>%
filter(!is.na(digital_index), YEAR >= 2013) %>%
group_by(YEAR, METRO) %>%
summarise(avg_index = mean(digital_index, na.rm = TRUE), .groups = "drop")
run_beta <- function(year_target) {
year_var <- paste0("y", year_target)
df <- metro_panel %>%
filter(YEAR %in% c(2013, year_target)) %>%
pivot_wider(names_from = YEAR, values_from = avg_index, names_prefix = "y") %>%
filter(!is.na(y2013), !is.na(!!sym(year_var))) %>%
mutate(change = !!sym(year_var) - y2013)
model <- lm(change ~ y2013, data = df)
data.frame(
year = year_target,
beta = coef(model)["y2013"],
p = summary(model)$coefficients["y2013", "Pr(>|t|)"],
r2 = summary(model)$r.squared
)
}
results <- do.call(rbind, lapply(2014:2023, run_beta))
ggplot(results, aes(x = year, y = beta)) +
geom_line(color = "steelblue", size = 1) +
geom_point(size = 2) +
geom_hline(yintercept = 0, linetype = "dashed") +
labs(
title = "Change in β-Convergence Slope over Time (METRO level)",
x = "Target Year (Compared to 2013)",
y = "β Coefficient (Slope)"
) +
theme_minimal()
# Packages Preparation
install.packages("ipumsr")
install.packages("tidyr")
library("tidyr")
library(ipumsr)
library(dplyr)
library(ggplot2)
library(readr)
ddi <- read_ipums_ddi("./data/raw_data/usa_00005.xml")
data <- read_ipums_micro(ddi)
ipums_data <- read_ipums_micro(ddi)
glimpse(ipums_data)
# Data Status
summary(ipums_data)
na_rates <- sapply(data, function(x) mean(is.na(x)))
na_df <- data.frame(variable = names(na_rates), na_rate = round(na_rates, 4))
na_df <- na_df[order(-na_df$na_rate), ]
head(na_df, 10)
data_recent <- data %>% filter(YEAR >= 2013)
na_rates_recent <- sapply(data_recent, function(x) mean(is.na(x)))
na_df_recent <- data.frame(
variable = names(na_rates_recent),
na_rate = round(na_rates_recent, 4)
)
na_df_recent <- na_df_recent[order(-na_df_recent$na_rate), ]
head(na_df_recent, 10)
# Data Processing(Only using 2013-now data for processing)
## Data Encoding
data_recent <- data_recent %>%
mutate(
cilaptop_bin = ifelse(CILAPTOP == 1, 1, ifelse(CILAPTOP == 0, 0, NA)),
cismrtphn_bin = ifelse(CISMRTPHN == 1, 1, ifelse(CISMRTPHN == 0, 0, NA)),
cidatapln_bin = ifelse(CIDATAPLN == 1, 1, ifelse(CIDATAPLN == 0, 0, NA)),
cihispeed_bin = case_when(
CIHISPEED %in% c(10, 20) ~ 1,
CIHISPEED == 0 ~ 0,
TRUE ~ NA_real_
)
)
## Drop URBAN Column
data_recent <- data_recent %>% select(-URBAN) # drop URBAN column
## Imputation for NA Values
data_recent <- data_recent %>%
mutate(
cismrtphn_bin = ifelse(is.na(cismrtphn_bin), 0, cismrtphn_bin)
)
## Construct Digital Index
data_recent <- data_recent %>%
rowwise() %>%
mutate(digital_index = mean(c(cilaptop_bin, cismrtphn_bin, cidatapln_bin, cihispeed_bin), na.rm = TRUE)) %>%
ungroup()
## Check the data again
summary(data_recent)
na_rates <- sapply(data_recent, function(x) mean(is.na(x)))
na_df <- data.frame(
variable = names(na_rates),
na_rate = round(na_rates, 4)
)
na_df <- na_df[order(-na_df$na_rate), ]
print(na_df)
# Final Cleaning
data_model <- data_recent %>%
drop_na(cilaptop_bin, cismrtphn_bin, cidatapln_bin, cihispeed_bin)
summary(data_model)
## Save the cleaned data to designated path
write_csv(data_model, "./data/cleaned_data/data_with_county.csv")
file.exists("./data/cleaned_data/data_with_county.csv")
install.packages("ipumsr")
install.packages("tidyr")
library(dplyr)
library(tidyr)
library(ggplot2)
library(readr)
data <- read_csv("./data/cleaned_data/data_with_county.csv")
# panel data construction (county-level)
county_panel <- data %>%
filter(!is.na(digital_index), !is.na(COUNTYFIP)) %>%
group_by(YEAR, COUNTYFIP) %>%
summarise(avg_digital_index = mean(digital_index, na.rm = TRUE), .groups = "drop")
# Compute signma
sigma_series <- county_panel %>%
group_by(YEAR) %>%
summarise(std_dev = sd(avg_digital_index, na.rm = TRUE))
# Visualization
ggplot(sigma_series, aes(x = YEAR, y = std_dev)) +
geom_line(color = "steelblue", size = 1.2) +
geom_point(size = 2) +
labs(
title = "County-Level σ-Convergence of Digital Index",
x = "Year",
y = "Standard Deviation across Counties"
) +
theme_minimal()
library(dplyr)
library(tidyr)
library(ggplot2)
library(readr)
data <- read_csv("./data/cleaned_data/data_with_county.csv")
# Panel Data Construction
county_panel <- data %>%
filter(YEAR %in% c(2013, 2023), !is.na(digital_index), !is.na(COUNTYFIP)) %>%
group_by(YEAR, COUNTYFIP) %>%
summarise(avg_index = mean(digital_index, na.rm = TRUE), .groups = "drop")
county_wide <- county_panel %>%
pivot_wider(names_from = YEAR, values_from = avg_index, names_prefix = "y") %>%
filter(!is.na(y2013), !is.na(y2023)) %>%
mutate(change = y2023 - y2013)
# Modeling
beta_model <- lm(change ~ y2013, data = county_wide)
summary(beta_model)
# Visualization
ggplot(county_wide, aes(x = y2013, y = change)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = TRUE, color = "steelblue") +
labs(
title = "County-Level β-Convergence of Digital Index (2013–2023)",
x = "Digital Index in 2013",
y = "Change in Digital Index (2023 - 2013)"
) +
theme_minimal()
# results
# write_csv(county_wide, "./data//county_beta_convergence_panel.csv")
# county_club_convergence.R
library(dplyr)
library(tidyr)
library(ggplot2)
library(readr)
library(clubcon)  # Phillips and Sul club convergence
# club_convergence.R
install.packages(clubcon)
library(dplyr)
library(tidyr)
library(ggplot2)
library(readr)
library(clubcon)  # Phillips and Sul club convergence
# club_convergence.R
install.packages("clubcon")
library(dplyr)
library(tidyr)
library(ggplot2)
library(readr)
library(clubcon)  # Phillips and Sul club convergence
library(dplyr)
library(tidyr)
library(ggplot2)
library(readr)
# library(clubcon)  # Phillips and Sul club convergence
install.packages("ConvergenceClubs")
library(ConvergenceClubs)
# club_convergence.R
# install.packages("clubcon")
library(dplyr)
library(tidyr)
library(ggplot2)
library(readr)
# library(clubcon)  # Phillips and Sul club convergence
install.packages("ConvergenceClubs")
library(ConvergenceClubs)
# loading the dataset
data <- read_csv("./data/cleaned_data/data_with_county.csv")
county_panel <- data %>%
filter(YEAR >= 2013, !is.na(digital_index), !is.na(COUNTYFIP)) %>%
group_by(YEAR, COUNTYFIP) %>%
summarise(avg_index = mean(digital_index), .groups = "drop")
club_mat <- county_panel %>%
pivot_wider(names_from = COUNTYFIP, values_from = avg_index) %>%
arrange(YEAR) %>%
column_to_rownames("YEAR") %>%
as.matrix()
library(tibble)
club_mat <- county_panel %>%
pivot_wider(names_from = COUNTYFIP, values_from = avg_index) %>%
arrange(YEAR) %>%
column_to_rownames("YEAR") %>%
as.matrix()
# convergence modeling
clubs <- findClubs(club_mat, dataCols = 1:ncol(club_mat),
time_trim = 1/3, HACmethod = "FQSB", cstar = 0)
# club_convergence.R
# 0. 安装并加载包
# install.packages("ConvergenceClubs")
library(dplyr)
library(tidyr)
library(ggplot2)
library(readr)
library(ConvergenceClubs)
library(tibble)
data <- read_csv("./data/cleaned_data/data_with_county.csv")
# panel data
county_panel <- data %>%
filter(YEAR >= 2013, !is.na(digital_index), !is.na(COUNTYFIP)) %>%
group_by(YEAR, COUNTYFIP) %>%
summarise(avg_index = mean(digital_index), .groups = "drop")
# transform to transition matrix
club_df <- county_panel %>%
pivot_wider(names_from = YEAR, values_from = avg_index) %>%
arrange(COUNTYFIP)
# save unit_names
unit_names <- club_df$COUNTYFIP
year_cols <- colnames(club_df)[-1]
club_mat <- as.matrix(club_df %>% select(-COUNTYFIP))
rownames(club_mat) <- unit_names
# convergence modeling
clubs <- findClubs(
X = cbind(County = unit_names, club_mat),
dataCols = 2:(ncol(club_mat)+1),
unit_names = 1,
refCol = ncol(club_mat) + 1,
time_trim = 1/3,
HACmethod = "FQSB",
cstar = 0
)
club_df <- county_panel %>%
pivot_wider(names_from = YEAR, values_from = avg_index) %>%
arrange(COUNTYFIP)
df_club <- club_df %>% select(COUNTYFIP, everything())
df_club <- as.data.frame(df_club)
# save unit_names
unit_names <- club_df$COUNTYFIP
year_cols <- colnames(club_df)[-1]
club_mat <- as.matrix(club_df %>% select(-COUNTYFIP))
rownames(club_mat) <- unit_names
# convergence modeling
clubs <- findClubs(
X = cbind(County = unit_names, club_mat),
dataCols = 2:(ncol(club_mat)+1),
unit_names = 1,
refCol = ncol(club_mat) + 1,
time_trim = 1/3,
HACmethod = "FQSB",
cstar = 0
)
# club_convergence.R
# --- 0. 安装并加载必要的包 ——
# 如果尚未安装，请取消注释以下行并执行：
# install.packages("ConvergenceClubs")
library(dplyr)
library(tidyr)
library(readr)
library(ConvergenceClubs)
library(ggplot2)
# --- 1. 读取已清洗数据 ——
data <- read_csv("./data/cleaned_data/data_with_county.csv")
# --- 2. 构建 county-year 面板数据，并计算每县年平均数字指数 ——
county_panel <- data %>%
filter(YEAR >= 2013, !is.na(digital_index), !is.na(COUNTYFIP)) %>%
group_by(YEAR, COUNTYFIP) %>%
summarise(avg_index = mean(digital_index, na.rm = TRUE), .groups = "drop")
# --- 3. 转换为宽格式 data.frame，每行代表一个县，列名为年份值 ——
club_df <- county_panel %>%
pivot_wider(names_from = YEAR, values_from = avg_index) %>%
arrange(COUNTYFIP) %>%
as.data.frame()  # 确保是 data.frame 而不是 tibble
# --- 4. 定义参数索引 ——
# 第一列是 County 名称，之后的列是各年份数据
dataCols <- 2:ncol(club_df)
refCol <- ncol(club_df)  # 使用最后一年作为排序参考
# --- 5. 运行 Phillips & Sul 的 club convergence 算法 ——
clubs <- findClubs(
X = club_df,
dataCols = dataCols,
unit_names = 1,
refCol = refCol,
time_trim = 1/3,
HACmethod = "FQSB",
cstar = 0
)
nrow(df)
